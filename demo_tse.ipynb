{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dd1fcc",
   "metadata": {},
   "source": [
    "# Sonification of Temporally Triggered Sound Events\n",
    "In numerous MIR applications one encounters cases where - for the time being not further specified - events occur at certain temporal positions. \n",
    "In this notebook, we illustrate how the `libsoni.core.tse` module can be used to sonify these events with different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8aeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import libfmp.b\n",
    "import libfmp.c4\n",
    "import librosa\n",
    "from IPython import display as ipd\n",
    "\n",
    "from libsoni.core.tse import sonify_tse_clicks, sonify_tse_multiple_clicks, sonify_tse_sample, sonify_tse_multiple_samples\n",
    "from libsoni.util.utils import mix_sonification_and_original, plot_sonify_novelty_beats\n",
    "\n",
    "AUDIO_DIR = 'data_audio'\n",
    "CSV_DIR = 'data_csv'\n",
    "Fs = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118bd267",
   "metadata": {},
   "source": [
    "## Simple Scenario: Time Positions\n",
    "To start with a simple example, let's create a list of arbitrarily chosen time positions, given in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1673664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some time positions\n",
    "time_positions = [0.5, 1.25, 2.5, 2.75]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40440a",
   "metadata": {},
   "source": [
    "### Sonification of Time Positions with Clicks\n",
    "Assuming we want to sonify this list, we can use the function `sonify_tse_clicks` to generate an audio signal comprising clicks at the corresponding time positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonification using libsoni\n",
    "sonified_time_positions = sonify_tse_clicks(time_positions=time_positions)\n",
    "\n",
    "print('Sonified time positions:')\n",
    "ipd.display(ipd.Audio(sonified_time_positions, rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61881cae",
   "metadata": {},
   "source": [
    "The clicks generated within `sonify_tse_click` can be adjusted in order to match the respective use case with the following parameters:\n",
    " - `click_pitch`: pitch of the click\n",
    " - `click_reverb_duration`: duration of the click\n",
    " - `click_amplitude`: amplitude of the click\n",
    " \n",
    "Let's say we'd rather have deeper sounding, longer clicks, the above sonification changes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonification using libsoni\n",
    "sample_sonified_time_positions = sonify_tse_clicks(time_positions=time_positions,\n",
    "                                                  click_pitch=51,\n",
    "                                                  click_fading_duration=0.5)\n",
    "\n",
    "print('Sonified time positions with deeper, longer clicks:')\n",
    "ipd.display(ipd.Audio(sample_sonified_time_positions, rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa773c",
   "metadata": {},
   "source": [
    "### Sonification of Time Positions with Samples\n",
    "Before we get to a real-world audio example, let's stay with the arbitrarily chosen time positions and explain how samples can be used for sonification.\n",
    "The first thing we need for this is - guess three times - a sample. Why don't we use a finger snap sound?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample\n",
    "snap_sample, _ = librosa.load(os.path.join(AUDIO_DIR,'samples', 'snap.wav'), sr=Fs)\n",
    "\n",
    "print('Snap sample:')\n",
    "ipd.display(ipd.Audio(snap_sample, rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31075481",
   "metadata": {},
   "source": [
    "Now, using the function `sonify_tse_sample` we can sonify our list of time positions with our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonification using libsoni\n",
    "sample_sonified_arbitrarily_chosen_time_positions = sonify_tse_sample(time_positions=time_positions,\n",
    "                                                                      sample=snap_sample)\n",
    "                                                 \n",
    "print('Sonified time positions with snap sample:')\n",
    "ipd.display(ipd.Audio(sample_sonified_arbitrarily_chosen_time_positions, rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45efbc",
   "metadata": {},
   "source": [
    "## Scenario 1: Sonifying Beat Annotations\n",
    "\n",
    "When it comes to applications that deal with tempo and rhythm, one often encounters so-called beat annotations. In the following example we show how these are sonified. The associated audio examples are excerpts from:\n",
    "\n",
    " - String Quartet No. 2, 3rd movement by Alexander Borodin\n",
    " - Mazurka in F Major, Op. 68 by Frédéric Chopin\n",
    " - Piano Quartet No. 1 in C minor, Op. 15 by Gabriel Fauré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff235c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borodin\n",
    "title = 'Borodin: String Quartet No. 2, 3rd movement' \n",
    "fn_ann = os.path.join(CSV_DIR, 'demo_tse', 'FMP_C6_Audio_Borodin-sec39_RWC_quarter.csv')\n",
    "fn_wav = os.path.join(AUDIO_DIR, 'demo_tse', 'FMP_C6_Audio_Borodin-sec39_RWC.wav')\n",
    "\n",
    "plot_sonify_novelty_beats(fn_wav, fn_ann, title);\n",
    "\n",
    "borodin_audio, _ = librosa.load(fn_wav, sr=Fs)\n",
    "borodin_df = pd.read_csv(fn_ann)\n",
    "\n",
    "# Sonification using libsoni\n",
    "sonified_borodin = sonify_tse_clicks(time_positions=borodin_df.to_numpy())\n",
    "\n",
    "print('Original audio and sonification of beat positions with clicks:')\n",
    "ipd.display(ipd.Audio(mix_sonification_and_original(sonified_borodin, borodin_audio, panning = 0.5), rate=Fs))\n",
    "\n",
    "# Chopin\n",
    "title = 'Chopin: Op.68, No. 3' \n",
    "fn_ann = os.path.join(CSV_DIR, 'demo_tse', 'FMP_C6_Audio_Chopin.csv')\n",
    "fn_wav = os.path.join(AUDIO_DIR, 'demo_tse', 'FMP_C6_Audio_Chopin.wav')\n",
    "\n",
    "plot_sonify_novelty_beats(fn_wav, fn_ann, title);\n",
    "\n",
    "chopin_audio, _ = librosa.load(fn_wav, sr=Fs)\n",
    "chopin_df = pd.read_csv(fn_ann)\n",
    "\n",
    "# Sonification using libsoni\n",
    "castanets_sample, _ = librosa.load(os.path.join(AUDIO_DIR,'samples', 'castanets.wav'), sr=Fs)\n",
    "sonified_chopin = sonify_tse_sample(time_positions=chopin_df.to_numpy(),\n",
    "                                    sample=castanets_sample)\n",
    "\n",
    "print('Original audio and sonification of beat positions with castanet sample:')\n",
    "ipd.display(ipd.Audio(mix_sonification_and_original(sonified_chopin, chopin_audio, panning = 0.5), rate=Fs))\n",
    "\n",
    "\n",
    "# Fauré\n",
    "title = 'Fauré: Op.15' \n",
    "fn_ann = os.path.join(CSV_DIR, 'demo_tse', 'FMP_C6_Audio_Faure_Op015-01-sec0-12_SMD126.csv')\n",
    "fn_wav = os.path.join(AUDIO_DIR, 'demo_tse', 'FMP_C6_Audio_Faure_Op015-01-sec0-12_SMD126.wav')\n",
    "\n",
    "plot_sonify_novelty_beats(fn_wav, fn_ann, title);\n",
    "\n",
    "faure_audio, _ = librosa.load(fn_wav, sr=Fs)\n",
    "faure_df = pd.read_csv(fn_ann)\n",
    "\n",
    "# Sonification using libsoni\n",
    "metronome_sample, _ = librosa.load(os.path.join(AUDIO_DIR, 'samples', 'metronome.wav'), sr=Fs)\n",
    "sonified_faure = sonify_tse_sample(time_positions=faure_df.to_numpy(),sample=metronome_sample)\n",
    "\n",
    "print('Original audio and sonification of beat positions with metronome sample:')\n",
    "ipd.display(ipd.Audio(mix_sonification_and_original(sonified_faure, faure_audio, panning = 0.5), rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e60fb8",
   "metadata": {},
   "source": [
    "## Scenario 2: Drumset - *Another One Bites The Dust* by *Queen*\n",
    "The possibilities of the module are not limited to the use of one sample. Why don't we sonify drums with `sonify_tse_multiple_samples`. The underlying annotation to Queen's Another one bites the tust describes time positions with labels of the respective played drums or cymbals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ffd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_ann = os.path.join(CSV_DIR, 'demo_tse', 'FMP_C6_F01_Queen_drums.csv')\n",
    "fn_wav = os.path.join(AUDIO_DIR, 'demo_tse', 'FMP_C6_Audio_Queen_AnotherOneBitesTheDust-Beginning.wav')\n",
    "\n",
    "queen_audio, _ = librosa.load(fn_wav, sr=Fs)\n",
    "print('Another one bites the dust by Queen:')\n",
    "ipd.display(ipd.Audio(queen_audio, rate=Fs))\n",
    "\n",
    "queen_drums_df = pd.read_csv(fn_ann, delimiter =';')\n",
    "print('Drums annotation:')\n",
    "ipd.display(queen_drums_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438ee62c",
   "metadata": {},
   "source": [
    "The `sonify_tse_multiple_samples` function takes a list consisting of tuples of one array of time positions and one array of the corresponding sample. In the next cell we show what such a data structure looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e639d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_times = queen_drums_df[queen_drums_df['label']=='kick']['position'].to_numpy()\n",
    "hihat_times = queen_drums_df[queen_drums_df['label']=='hihat']['position'].to_numpy()\n",
    "snare_times = queen_drums_df[queen_drums_df['label']=='snare']['position'].to_numpy()\n",
    "\n",
    "hihat_sample, _ = librosa.load(os.path.join(AUDIO_DIR, 'samples', 'hi-hat.wav'),sr=Fs)\n",
    "snare_sample, _ = librosa.load(os.path.join(AUDIO_DIR, 'samples', 'snare.wav'),sr=Fs)\n",
    "kick_sample, _ = librosa.load(os.path.join(AUDIO_DIR, 'samples', 'bass-drum.wav'),sr=Fs)\n",
    "\n",
    "kick_tuple = (kick_times, kick_sample)\n",
    "snare_tuple = (snare_times, snare_sample)\n",
    "hihat_tuple = (hihat_times, hihat_sample)\n",
    "\n",
    "\n",
    "queen_drums = [hihat_tuple, kick_tuple, snare_tuple]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b58f5ff",
   "metadata": {},
   "source": [
    "### Sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ff15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_sonified = sonify_tse_multiple_samples(queen_drums)\n",
    "\n",
    "print('Original audio:')\n",
    "ipd.display(ipd.Audio(queen_audio,rate=Fs))\n",
    "\n",
    "print('Sonified drums annotation with libsoni:')\n",
    "ipd.display(ipd.Audio(queen_sonified,rate=Fs))\n",
    "\n",
    "print('Original audio with sonification (stereo):')\n",
    "ipd.display(ipd.Audio(mix_sonification_and_original(queen_audio, queen_sonified),rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812caec",
   "metadata": {},
   "source": [
    "## Scenario 3: Structure Annotations aux *Town Musicians of Bremen*\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"margin-top: 20px;\">\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "        <div style=\"flex: 1; text-align: center;padding-right: 20px;\">\n",
    "            <img src=\"figures/demo_tse/town_musicians_of_bremen.png\" alt=\"Image\" style=\"width: 95%; max-width: 400px;\"/>\n",
    "        </div>\n",
    "        <div style=\"flex: 1;\">\n",
    "            <p style=\"text-align: left-align; max-width: 800px;\">\n",
    "            The \"Town Musicians of Bremen\" is a famous German folk tale collected by the Brothers Grimm. It tells the story of four aging animals – a donkey, a dog, a cat, and a rooster – who, having outlived their usefulness to their owners, embark on a journey to Bremen to become musicians. In the next example, we have so-called structure annotations that identify individual passages of Frédéric Chopin's Op. 28 No. 11 in B major, also known as Prelude No. 11. For more details about the structure annotations, see the FMP Notebook <a href=\"https://www.audiolabs-erlangen.de/resources/MIR/FMP/C4/C4S1_MusicStructureGeneral.html\">Music Structure Analysis: General Principles</a>. The Bremen Town Musicians and Frédéric Chopin may have little to do with each other, but nevertheless we use characteristic sound samples of the animals to mark the beginnings of different structural passages.\n",
    "            </p>\n",
    "        </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_ann = os.path.join(CSV_DIR, 'demo_tse', 'FMP_C4_Audio_Chopin_Op028-11_003_20100611-SMD.csv')\n",
    "chopin_df = pd.read_csv(fn_ann, delimiter=';')\n",
    "\n",
    "ann, color_ann = libfmp.c4.read_structure_annotation(fn_ann)\n",
    "ipd.display(chopin_df)\n",
    "\n",
    "fn_wav = os.path.join(AUDIO_DIR, 'demo_tse', 'FMP_C4_Audio_Chopin_Op028-11_003_20100611-SMD.wav')\n",
    "chopin_audio, _ = librosa.load(fn_wav, sr=Fs)\n",
    "\n",
    "times_A = chopin_df[chopin_df['label'] == 'A']['start'].to_numpy()\n",
    "times_B = chopin_df[chopin_df['label'] == 'B']['start'].to_numpy()\n",
    "times_C = chopin_df[chopin_df['label'] == 'C']['start'].to_numpy()\n",
    "times_D = chopin_df[chopin_df['label'] == 'D']['start'].to_numpy()\n",
    "\n",
    "sample_A, _ = librosa.load(os.path.join(AUDIO_DIR, 'samples', 'rooster.wav'), sr=Fs)\n",
    "sample_B, _ = librosa.load(os.path.join(AUDIO_DIR, 'samples', 'cat.wav'), sr=Fs)\n",
    "sample_C, _ = librosa.load(os.path.join(AUDIO_DIR, 'samples', 'dog.wav'), sr=Fs)\n",
    "sample_D, _ = librosa.load(os.path.join(AUDIO_DIR, 'samples', 'donkey.wav'), sr=Fs)\n",
    "\n",
    "collection = [(times_A, sample_A),(times_B, sample_B),(times_C, sample_C),(times_D, sample_D)]\n",
    "\n",
    "sonification_bremen = sonify_tse_multiple_samples(collection, offset_relative=0.5)\n",
    "\n",
    "color_ann = {'A': [1, 0, 0, 0.2],'B': [0, 1, 0, 0.2],  'C': [0, 0, 1, 0.2], 'D': [1, 1, 0, 0.2]}\n",
    "\n",
    "\n",
    "fig, ax = libfmp.b.plot_segments(ann, colors=color_ann, figsize=(6, 1))\n",
    "plt.xlabel('Time (frames)');\n",
    "plt.show()\n",
    "\n",
    "ipd.display(ipd.Audio(mix_sonification_and_original(sonification_bremen, chopin_audio, panning = 0.5), rate=Fs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
